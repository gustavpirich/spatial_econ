---
title: '**Spatial Economics -- Assignment 2**'
author: 
  - "Gustav Pirich (h11910449)"
  - "Peter Prlleshi ()"
  - "Filip Lukijanovic ()"
date: "April 2, 2024"
output: 
  pdf_document:
    toc: true
    includes:
      in_header: !expr file.path("~/Desktop/GITHUB/spatial_econ/helper/wraper_code.tex")
header-includes: 
  - \usepackage{tcolorbox}
  - \usepackage[default]{lato}
papersize: a4
geometry: margin = 2cm
urlcolor: DarkOrchid!65!black
---

```{r, setup, include = FALSE}
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
knitr::opts_chunk$set(tidy.opts = list(width.cutoff = 80), tidy = TRUE)
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
library(showtext)
showtext_auto()

library(sf)
library(tidyverse)
library(tmap)
library(viridis)
library(spdep)
library(igraph)
library(spdep)
library(generics)
library(knitr)
library(kableExtra)
library(haven)
```

\vspace{2em}

\begin{tcolorbox}
\centering \itshape The code that was used in compiling the assignment is available on GitHub at \url{https://github.com/gustavpirich/spatial_econ/blob/main/02_assignment/02_assignmnet.Rmd}.
\end{tcolorbox}

\newpage

# Exercise A

```{r, echo = FALSE}
#reading in spatial dimension of productivity growth
load("~/Desktop/GITHUB/spatial_econ/data/02_assignmnet/Assignment___export/data1.rda")

#reading in Shapefile of EU-27
EU27 <- read_sf("~/Desktop/GITHUB/spatial_econ/data/02_assignmnet/Assignment___export/EU27.shp")

# we can also exclude all oversea territories
overseas <- c("FRY1", "FRY2", "FRY3", "FRY4", "FRY5", "FRZZ", 
              "PT20", "PT30", "PTZZ", 
              "ES70", "ESZZ", 
              "NO0B", "NOZZ")

east_germany_nuts2 <- c("DE40", "DE80", "DED3", "DED2", "DED1","DE42", "DE41", "DE30", "DED5", "DEE0", "DEG0", "DEE3", "DEE2", "DEE1")

EU27 <- EU27[! EU27$Id %in% overseas, ]
  
data1 <- data1[! data1$IDb %in% overseas, ]

data_1 <- data1 %>%
  filter(substr(IDb, 1, 2) %in% c("AT", "DE", "IT", "PT", "FR", "ES")) %>%
  select(IDb, pr80b, pr103b, lninv1b, lndens.empb) %>%
  rename("Id" = "IDb") %>%
  filter(!Id %in% east_germany_nuts2)

data_1$prod_growth <- (data_1$pr103b - data_1$pr80b) / data_1$pr80b

EU27 <- EU27 %>%
  filter(substr(Id, 1, 2) %in% c("AT", "DE", "IT", "PT", "FR", "ES")) %>%
  filter(!Id %in% east_germany_nuts2) %>%
  left_join(data_1, by = c("Id"))

```
## Calculate the growth rate of productivity from 1980 to 2013 and create a map that shows the productivity growth for each region. 

The map shows the productivity growth rates in the NUTS-2 regions for the selected countries. We can see that many regions especially in Germany, Austria, and France exhibited negative productivity growth over the selected time period. Notably, Portugal's productivity has been growing the fastest. We suspect that the negative growth rates can be explained by the fact that high-income countries had a high baseline productivity to being with, while Portugal had a low baseline productivity. This could be evidence of convergence among productivity differences across Europe.

```{r,echo = FALSE}
tm_shape(EU27) +
  tm_polygons("prod_growth", 
              title = "Productivity Growth",
              style = "cont", 
              lwd = 2) +
  tm_legend(position = c("left", "bottom"), legend.outside = TRUE) +
  tm_layout(frame = TRUE, bg.color = "lightblue") 
```

## Generate three different spatial weights matrixes using (i) a distance threshold, (ii) smooth distance-decay, and iii) a contiguity-based measure. 


### (i) Distance Threshold 
First, we create a binary distance threshol spatial weights matrix based. Any region is being assigned a '1', if the center of any other region is less than 3 km away. Note that we have chosen this value so that every region has a neighbor. We use the nb2mat function from the 'spdep' package. We row-normalize the matrix.

```{r, echo = FALSE}
coords <- st_coordinates(st_centroid(EU27))

#checking the maximum distance as to include all observations which have a matrix   
nb1 <- knn2nb(knearneigh(coords, k = 1))

dist1 <- nbdists(nb1, coords)
summary(unlist(dist1))

distw <- dnearneigh(coords, 0, 3, row.names=EU27$Id)

#creating matrix based on distance threshold up to 3 kilometers
dist_w_matrix <- nb2mat(distw, style="W", zero.policy=TRUE)
```


### (ii) Smooth-Distance Decay 
Next, we create a spatial weights matrix based on a smooth distance-decay. We use the following simple distance decay function $w_{i, j} (d) = 1/d$. We calculate the weights for each neighboring region based on the k=1 nearest neighbors. We do not row-normalize the matrix.

```{r, echo = FALSE}
wm_q <- poly2nb(EU27, queen = TRUE, row.names = EU27$Id)

#summary(wm_q)

#k2 <- knn2nb(knearneigh(coords, k = 1), row.names = EU27$Id)

dists <- nbdists(wm_q, coords)

ids <- lapply(dists, function(d){1/d})

decay_weights_matrix_list <- nb2listw(wm_q, glist = ids, style = "B", zero.policy = TRUE)

decay_weights_matrix <- listw2mat(decay_weights_matrix_list)
```

### (iii) Contiguity-based measure
Finally, we calculate a contiguity based measure, which we row normalize as well.
```{r, echo = FALSE}
# Create a contiguity-based spatial weights matrix
queen_weights <- poly2nb(EU27, queen = TRUE, row.names = EU27$Id)

contig_w_matrix <- nb2mat(queen_weights, style="W", zero.policy=TRUE)
```

## Compare the matrices; use your knowledge of graph theory and linear algebra
```{r,echo = FALSE, results = "asis"}
# Convert to igraph objects for graph analysis
graph_dist <- graph_from_adjacency_matrix(dist_w_matrix, mode = "undirected", weighted = TRUE, add.rownames = "code")
graph_decay <- graph_from_adjacency_matrix((decay_weights_matrix), mode = "undirected")
graph_contig <- graph_from_adjacency_matrix(contig_w_matrix, mode = "undirected", weighted = TRUE)

# Function to summarize graph properties
summarize_graph <- function(g) {
  cat("Number of vertices:", vcount(g), "\n")
  cat("Number of edges:", ecount(g), "\n")
  cat("Average path length:", average.path.length(g, directed = FALSE), "\n")
  cat("Graph density:", edge_density(g), "\n")
  cat("Average degree:", mean(degree(g)), "\n")
  
  # Compute Eigenvector Centrality
  ec <- eigen_centrality(g)
  cat("Max Eigenvector Centrality:", max(ec$vector), "\n")
  cat("Min Eigenvector Centrality:", min(ec$vector), "\n")
  cat("Average Eigenvector Centrality:", mean(ec$vector), "\n")
  
  # Identify the most central unit
  max_centrality_index <- which.max(ec$vector)
  most_central_unit <- V(g)[max_centrality_index]
  cat("Most Central Unit (Vertex ID):", as.numeric(most_central_unit), "\n")
  cat("Most Central Unit (Vertex Name):", V(g)$name[max_centrality_index], "\n")
}


# Analyze graph properties
cat("Distance Threshold Graph:\n")
summarize_graph(graph_dist)
cat("\nSmooth Distance-Decay Graph:\n")
summarize_graph(graph_decay)
cat("\nContiguity-Based Graph:\n")
summarize_graph(graph_contig)
```
We compare the matrices based on a set of characteristics.The Distance Threshold Graph has 514 edges, indicating a higher level of connections between vertices compared to the other two. This suggests that many vertices are within the distance threshold to be considered neighbors.
Smooth Distance-Decay 
Graph has only 40 edges, significantly fewer than the other graphs. This implies a much stricter criterion for considering two vertices to be connected, likely reflecting a much tighter control over distance decay effects. Contiguity-Based Graph strikes a balance with 222 edges, suggesting its connectivity criteria (likely based on shared boundaries or proximities) result in a moderate level of connections.
Average Path Length 
Distance Threshold Graph shows a very low average path length (0.6750662), meaning that, on average, vertices are closely connected, allowing for short paths between them.
Smooth Distance-Decay Graph has a much higher average path length (4.531818), indicating that paths between vertices are generally longer, reflecting the sparse connections.
Contiguity-Based Graph has an average path length (1.288804), which is between the other two, suggesting moderate ease of movement across the graph compared to the other types.
Graph Density
Distance Threshold Graph has a density of 0.09784885, which is higher than the others, reflecting its higher number of edges and suggesting a relatively dense network.
Smooth Distance-Decay Graph is the sparsest, with a density of 0.007614696, aligning with its fewer edges and longer path lengths.
Contiguity-Based Graph has a density of 0.04226156, which, while lower than the distance threshold graph, suggests a moderately dense network, possibly due to its criteria for connections.
Average Degree
Distance Threshold Graph has a high average degree (9.980583), suggesting that, on average, each vertex is directly connected to about 10 other vertices, indicating a high level of connectivity.
Smooth Distance-Decay Graph has a low average degree (0.776699), showing that each vertex is connected to less than one vertex on average, emphasizing its sparse nature.
Contiguity-Based Graph has an average degree of 4.31068, indicating moderate connectivity among its vertices.
Comparison Summary
Connectivity: The Distance Threshold Graph is the most connected, followed by the Contiguity-Based Graph, with the Smooth Distance-Decay Graph being the least connected.
Cohesion: Measured by average path length and graph density, the Distance Threshold Graph shows the highest cohesion, indicating that it's easier to traverse between any two vertices. The Smooth Distance-Decay Graph has the lowest cohesion, with the Contiguity-Based Graph in the middle.
Application Suitability: The Distance Threshold Graph may be best suited for scenarios where the emphasis is on the close and dense connections between locations. The Smooth Distance-Decay Graph might be preferred for studies focusing on the impact of distance, favoring sparse connections that significantly weaken with distance. The Contiguity-Based Graph could be suitable for applications where geographical contiguity or proximity is a primary concern, such as regional planning.
Each graph type, therefore, offers distinct advantages and drawbacks, depending on the specific requirements of your spatial analysis or modeling efforts.


## Plot the matrix
We now plot the three spatial weight matrices. We see that the distance decay weight matrix is symmetric. The distance decay matrix is 
```{r, echo = FALSE, fig.align = 'center', fig.width=5, fig.height=4}
# Plotting each matrix
image(dist_w_matrix , main="Distance Threshold Spatial Weights Matrix")
image(decay_weights_matrix, main="Smooth Distance-Decay Spatial Weights Matrix")
image(contig_w_matrix, main="Contiguity-Based Spatial Weights Matrix")
#lattice::levelplot(t(dist_w_matrix),
#scales = list(y = list(at = c(10, 30, 50, 70),
#                       labels = c(10, 20, 30, 40))))

#lattice::levelplot(t(decay_weights_matrix),
#scales = list(y = list(at = c(10, 30, 50, 70),
#                       labels = c(10, 20, 30, 40))))

#lattice::levelplot(t(contig_w_matrix),
#scales = list(y = list(at = c(10, 30, 50, 70),
#                       labels = c(10, 20, 30, 40))))
```
## Try to visualize the network they represent

Let us first visualize the distance based spatial matrix. The first plot shows the map of Europe and the blue lines indicate the connections. The map shows the connectivity in Europe based on the distance threshold. 

The second map visualizes the network based on the distance decay matrix. However, the edges do not display the intensity of connections, but just the connectivity to neighboring regions. 

The last map displays the queen contiguity based measure. Interestingly, the islands in the middle sea are not being counted as neighbors. This should caution the use of this network,m as it seems implausible that Silicy for example is mainland italian provinces.  
```{r,echo = FALSE, fig.width=9, fig.height=13, fig.align='center'}
par(mfrow = c(3, 1), las=1)

plot(EU27$geometry, border = "darkgrey", main = "Distance Threshold")
plot(distw, coords, add=TRUE, col="blue", pch = 19, cex = 0.6)

plot(EU27$geometry, border = "darkgrey", main = "Distance Decay")
plot(decay_weights_matrix_list, coords, add=TRUE, col= "green", pch = 19, cex = 0.6)

plot(EU27$geometry, border = 'darkgrey', main = "Queen Contiguity") 
plot(queen_weights, coords, pch = 19, cex = 0.6, add = TRUE, col = "red")
```

## Compute a suitable measure of spatial autocorrelation for productivity growth using these matrices. Point out differences, if there are any. 

We calculate Global Moran's I as a measure of spatial autocorrelation for all three spatial weight matrices.  All three matrices display the strong positive spatial autocorrelation between 0.62 - 0.54, which are all highly statistically significant with p-values < 0.01. Thus there is strong evidence for the presence of sizeable levels of spatial autocorrelation. This result is robust to the choice of the spatial weights matrix. 
```{r,echo = FALSE}
# Convert the matrix to a listw object
l_dist_w_matrix <- mat2listw(dist_w_matrix, style = "B", zero.policy = TRUE)

l_decay_weights_matrix <- mat2listw(decay_weights_matrix, zero.policy = TRUE, style = "B")

l_contig_w_matrix <- mat2listw(contig_w_matrix, zero.policy = TRUE, style = "W")

# Compute Global Moran's I
moran_result_dist <- moran.test((EU27$prod_growth), listw = l_dist_w_matrix)

moran_result_decay <- moran.test((EU27$prod_growth), listw = l_decay_weights_matrix)

moran_result_contig <- moran.test((EU27$prod_growth), listw = l_contig_w_matrix)

# Create a data frame to hold the summarized results
moran_summary <- data.frame(
  Test = c("Distance Threshold", "Smooth Distance-Decay", "Contiguity-Based"),
  Moran_I = c(moran_result_dist$estimate["Moran I statistic"], 
              moran_result_decay$estimate["Moran I statistic"], 
              moran_result_contig$estimate["Moran I statistic"]),
  Expectation = c(moran_result_dist$estimate["Expectation"], 
                  moran_result_decay$estimate["Expectation"], 
                  moran_result_contig$estimate["Expectation"]),
  Variance = c(moran_result_dist$estimate["Variance"], 
               moran_result_decay$estimate["Variance"], 
               moran_result_contig$estimate["Variance"]),
  p_value = c(moran_result_dist$p.value, 
              moran_result_decay$p.value, 
              moran_result_contig$p.value)
)

# Format and print the table
kable(moran_summary, "latex", digits = 4, booktabs = TRUE) %>%
  kable_styling(latex_options = c("striped", "scale_down")) %>%
  column_spec(1, bold = TRUE, border_right = TRUE) %>%
  column_spec(5, color = ifelse(moran_summary$p_value < 0.05, "red", "black"))
```
## Estimate a linear regression model using OLS. 
We estimate the specified model and obtain the following output.
\begin{table}[!htbp] \centering 
  \caption{} 
  \label{} 
\begin{tabular}{@{\extracolsep{5pt}}lc} 
\\[-1.8ex]\hline 
\hline \\[-1.8ex] 
 & \multicolumn{1}{c}{\textit{Dependent variable:}} \\ 
\cline{2-2} 
\\[-1.8ex] & prod\_growth \\ 
\hline \\[-1.8ex] 
 pr80b & $-$0.253$^{***}$ \\ 
  & (0.025) \\ 
  & \\ 
 lninv1b & 0.032$^{***}$ \\ 
  & (0.008) \\ 
  & \\ 
 lndens.empb & 0.007 \\ 
  & (0.009) \\ 
  & \\ 
 Constant & 0.314$^{***}$ \\ 
  & (0.061) \\ 
  & \\ 
\hline \\[-1.8ex] 
Observations & 103 \\ 
R$^{2}$ & 0.528 \\ 
Adjusted R$^{2}$ & 0.514 \\ 
Residual Std. Error & 0.080 (df = 99) \\ 
F Statistic & 36.983$^{***}$ (df = 3; 99) \\ 
\hline 
\hline \\[-1.8ex] 
\textit{Note:}  & \multicolumn{1}{r}{$^{*}$p$<$0.1; $^{**}$p$<$0.05; $^{***}$p$<$0.01} \\ 
\end{tabular} 
\end{table} 

We observe strong evidence for spatial autocorrelation. This holds for all spatial weights matrices used. The different weighting schemes highlight differnt countries. Thus the neglect fo this spatial dimension might give rise to bias in the OLS estimated coefficients.  

```{r,echo = FALSE, fig.width=9, fig.height=13, fig.align='center'}
sm <- lm(prod_growth ~ pr80b + lninv1b + lndens.empb, EU27)

# Set layout to 2x2 and adjust margins and label orientation
par(mfrow = c(3, 1), las=1)
#stargazer::stargazer(sm, type = "latex")
moran.plot(sm$residuals, l_dist_w_matrix, xlab = "Residuals", ylab = "Spatially Lagged Residuals")

moran.plot(sm$residuals, l_decay_weights_matrix, xlab = "Residuals", ylab = "Spatially Lagged Residuals")

moran.plot(sm$residuals, l_contig_w_matrix, xlab = "Residuals", ylab = "Spatially Lagged Residuals")
```

# Exercise B

## Creating maps
```{r, echo = FALSE}
literacy_Arg_Bra_Par <- read_dta("data/02_assignmnet/export/literacy_Arg-Bra-Par.dta", encoding = "ISO-8859-1")

#downloading the respective shapefiles take care of the file paths!!!

gadm41_PRY_2 <- read_sf("/Users/gustavpirich/Library/Mobile Documents/com~apple~CloudDocs/Wirtschaftsuniversitaet/MASTER/summer_term_2024/spatial_economics/data/boundaries/gadm41_PRY_shp/gadm41_PRY_2.shp")

gadm41_ARG_2 <- read_sf("/Users/gustavpirich/Library/Mobile Documents/com~apple~CloudDocs/Wirtschaftsuniversitaet/MASTER/summer_term_2024/spatial_economics/data/boundaries/gadm41_ARG_shp/gadm41_ARG_2.shp")

gadm41_BRA_2 <- read_sf("/Users/gustavpirich/Library/Mobile Documents/com~apple~CloudDocs/Wirtschaftsuniversitaet/MASTER/summer_term_2024/spatial_economics/data/boundaries/gadm41_BRA_shp/gadm41_BRA_2.shp")

dat <- rbind(gadm41_PRY_2,gadm41_ARG_2,gadm41_BRA_2)

dat_1 <- dat %>%
  filter(NAME_1 %in% c("Misiones", "Corrientes", "Rio Grande do Sul", "Itap√∫a"))

list_1 <- dat_1 %>%
  select(COUNTRY, geometry, NAME_2) 

literacy_Arg_Bra_Par <- literacy_Arg_Bra_Par %>%
  rename("NAME_2" = "muni") %>%
  rename("COUNTRY" = "country")

#merging the data
literacy_Arg_Bra_Par_1 <- left_join(literacy_Arg_Bra_Par, list_1, by = c("NAME_2", "COUNTRY"))
```

```{r}
view(literacy_Arg_Bra_Par_1)

```